# -*- coding: utf-8 -*-
"""TD5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jyIqJQH_ze0fKsdFJ5h_dp3oO8077NHp
"""

# Commented out IPython magic to ensure Python compatibility.
try:
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
from tensorflow import keras

#ex1
import pandas as pd
import io
import matplotlib.pyplot as plt
from google.colab import files

uploaded = files.upload()

wine = pd.read_csv(io.BytesIO(uploaded['winequality-white.csv']),
                   sep=';')

wine.head()

from sklearn.utils import shuffle

wine = shuffle(wine)

wine.head()

#ex2
plt.scatter(wine['fixed acidity'],
            wine['alcohol'],
            c=wine['quality'],
            cmap='viridis')

plt.xlabel("fixed acidity")
plt.ylabel("alcohol")
plt.show()

#ex3
from keras.utils import to_categorical
x=wine.iloc[:,:10]
y=wine.iloc[:,11:]


x=x.values
y=y.values

y = to_categorical(y)
y

#ex4
n_train = 4000
trainX, testX = x[:n_train, :] , x[n_train:, :]
trainY, testY = y[:n_train] , y[n_train:]

#ex5
model= keras.Sequential([keras.layers.Dense(11),
                         keras.layers.Dense(50, activation='relu'),
                         keras.layers.Dense(10, activation='softmax')
                         ])

#ex6
from keras.optimizers import SGD

lrate = 0.001
model.compile(loss='categorical_crossentropy',
              optimizer=keras.optimizers.SGD(learning_rate=lrate), metrics=['accuracy'])

#ex7
print (trainX)
history=model.fit(trainX, trainY, validation_data=(testX, testY),epochs=200, verbose=2)

#ex8
plt.plot(history.history['acc'], label='train',color = 'r')
plt.plot(history.history['val_acc'], label='test', color = 'b')
plt.title('lrate='+str(lrate), pad=-50)

#ex9
def fit_model(trainX, trainy, testX, testy,lrate):
  model= keras.Sequential([keras.layers.Dense(11),
                         keras.layers.Dense(50, activation='relu'),
                         keras.layers.Dense(10, activation='softmax')
                         ])
  
  model.compile(loss='categorical_crossentropy',
              optimizer=keras.optimizers.SGD(learning_rate=lrate), metrics=['accuracy'])
  
  history=model.fit(trainX, trainY, validation_data=(testX, testY),epochs=200, verbose=0)

  plt.plot(history.history['acc'], label='train',color = 'r')
  plt.plot(history.history['val_acc'], label='test', color = 'b')
  plt.title('lrate='+str(lrate), pad=-50)

#ex10
learning_rates = [1E-0, 1E-1, 1E-2, 1E-3, 1E-4, 1E-5, 1E-6, 1E-7]
for i in  range(len(learning_rates)):
  plot_no = 420 + (i+1)
  plt.subplot(plot_no)
  fit_model(trainX , trainY , testX , testY , learning_rates[i])
  plt.show()

