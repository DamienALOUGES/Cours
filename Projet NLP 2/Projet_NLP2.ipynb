{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet_NLP2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeacIV20OyYd"
      },
      "source": [
        "# Importation et pré-processings du projet 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRy-l9AfO_XN"
      },
      "source": [
        "## Importation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0S7vEFJ2Qka"
      },
      "source": [
        "import pandas as pd \n",
        "import xml.etree.ElementTree as et\n",
        "from lxml import etree\n",
        "import re\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tree1 = etree.parse(\"corpus_taln_v2.tei.xml\")\n",
        "#tree2 = etree.parse(\"exemple-article.xml\")\n",
        "\n",
        "df_cols = [\"abstract_fr\", \"keywords_fr\", \"intro\", \"titre\", \"date\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZKvTWXiy5lT"
      },
      "source": [
        "def text_cleaner(string):\n",
        "  if string != None :\n",
        "    string = string.translate(str.maketrans(\"\\n\\t\", \"  \"))\n",
        "  elif string == None:\n",
        "    string = \"None\"\n",
        "  return (string)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Zk9DdMDIyA"
      },
      "source": [
        "rows=[]\n",
        "compteur_article = 0\n",
        "\n",
        "root = tree1.getroot()\n",
        "for article in root:\n",
        "  intro = \"\"\n",
        "  abstract_fr = \"\"\n",
        "  keywords_fr = \"\"\n",
        "  titre = \"\"\n",
        "\n",
        "  #print(article[0].attrib)\n",
        "  #print(article[0].tag)\n",
        "  #print(article[1][0][0][0].text)\n",
        "\n",
        "  abstract_fr = article[1][0][0][0].text\n",
        "  keywords_fr = article[1][0][2][0].text\n",
        "\n",
        "  abstract_fr= text_cleaner(abstract_fr)\n",
        "  keywords_fr= text_cleaner(keywords_fr)\n",
        "\n",
        "  try :\n",
        "    intro = article[1][1][0][1].text\n",
        "    intro = text_cleaner(intro)\n",
        "  except :\n",
        "    oui = 0\n",
        "  \n",
        "  titre = article[0][0][0][0].text\n",
        "  titre = text_cleaner(titre)\n",
        "\n",
        "  try : \n",
        "    date= article[0][0][1][2].text\n",
        "    date = text_cleaner(date)\n",
        "  except :\n",
        "    oui = 0\n",
        "\n",
        "  rows.append({\"abstract_fr\": abstract_fr, \"keywords_fr\":keywords_fr, \"intro\": intro, \"titre\": titre, \"date\":date})\n",
        "  compteur_article += 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "_QwoDA2oDI8H",
        "outputId": "28c501f6-e89d-4726-d435-8adce452aa15"
      },
      "source": [
        "df = pd.DataFrame(rows, columns = df_cols)\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract_fr</th>\n",
              "      <th>keywords_fr</th>\n",
              "      <th>intro</th>\n",
              "      <th>titre</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nous considérons dans notre travail la tâche ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Le modèle de la Grammaire Applicative et Cogn...</td>\n",
              "      <td>Éléments de conception d'un système d'interpr...</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nous donnons ici un aperçu du logiciel DECID ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Dans le domaine de l'ingénierie linguistique ...</td>\n",
              "      <td>Informatisation du dictionnaire explicatif et...</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Diverses méthodes ont été proposées pour cons...</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>Construction d'une représentation sémantique ...</td>\n",
              "      <td>1997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Le terme de lambda-DRT désigne un ensemble de...</td>\n",
              "      <td>None</td>\n",
              "      <td>La « Théorie des Représentations Discursives ...</td>\n",
              "      <td>Systèmes de types pour la (lambda-)DRT ascend...</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dans cet article, nous comparons deux modèles...</td>\n",
              "      <td>None</td>\n",
              "      <td>TAG est un formalisme initialement développé ...</td>\n",
              "      <td>Une grammaire TAG vue comme une grammaire Sen...</td>\n",
              "      <td>1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>Dans cet article, nous présentons une approch...</td>\n",
              "      <td>Curriculum d'apprentissage, transfert d'appre...</td>\n",
              "      <td>L'apprentissage humain est réalisé par étapes...</td>\n",
              "      <td>Curriculum d'apprentissage : reconnaissance d...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>Cet article présente une méthodologie de déte...</td>\n",
              "      <td>ellipse, anglais, corpus, sous-titres, détect...</td>\n",
              "      <td>L'ellipse renvoie à une incomplétude syntaxiq...</td>\n",
              "      <td>Détection des ellipses dans des corpus de sou...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599</th>\n",
              "      <td>La génération automatique de poésie est une t...</td>\n",
              "      <td>génération de poésie, réseaux de neurones, fa...</td>\n",
              "      <td>La génération automatique de poésie est une t...</td>\n",
              "      <td>La génération automatique de poésie en français</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1600</th>\n",
              "      <td>Nous proposons une architecture neuronale ave...</td>\n",
              "      <td>Réseaux neuronaux, modélisation de séquences,...</td>\n",
              "      <td>L'étiquetage de séquences est un problème imp...</td>\n",
              "      <td>Modèles neuronaux hybrides pour la modélisati...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1601</th>\n",
              "      <td>Nous présentons la base PolylexFLE, contenant...</td>\n",
              "      <td>expressions polylexicales vebales, niveau CEC...</td>\n",
              "      <td>Les expressions polylexicales (EP) constituen...</td>\n",
              "      <td>PolylexFLE : une base de données d'expression...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1602 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            abstract_fr  ...  date\n",
              "0      Nous considérons dans notre travail la tâche ...  ...  1997\n",
              "1      Nous donnons ici un aperçu du logiciel DECID ...  ...  1997\n",
              "2      Diverses méthodes ont été proposées pour cons...  ...  1997\n",
              "3      Le terme de lambda-DRT désigne un ensemble de...  ...  1998\n",
              "4      Dans cet article, nous comparons deux modèles...  ...  1998\n",
              "...                                                 ...  ...   ...\n",
              "1597   Dans cet article, nous présentons une approch...  ...  2019\n",
              "1598   Cet article présente une méthodologie de déte...  ...  2019\n",
              "1599   La génération automatique de poésie est une t...  ...  2019\n",
              "1600   Nous proposons une architecture neuronale ave...  ...  2019\n",
              "1601   Nous présentons la base PolylexFLE, contenant...  ...  2019\n",
              "\n",
              "[1602 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUlxw0O-4j_q",
        "outputId": "ad4fcba4-b4b7-4770-b179-127961270841"
      },
      "source": [
        "compteur_article"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_Qc2Tm-PF1N"
      },
      "source": [
        "## Génération de keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHzqNyugh8q4"
      },
      "source": [
        "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
        "\n",
        "replacement_patterns = [\n",
        "(r'd\\'', 'de '),\n",
        "(r'l\\'', 'le '),\n",
        "(r'qu\\'', 'que '),\n",
        "(r',', ''),\n",
        "(r'-', ' '),\n",
        "(r'\\.', ''),\n",
        "(r'\\;', '')\n",
        "]\n",
        "\n",
        "class RegexpReplacer(object):\n",
        "   def __init__(self, patterns=replacement_patterns):\n",
        "      self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
        "\n",
        "   def replace(self, text):\n",
        "      s = text\n",
        "      for (pattern, repl) in self.patterns:\n",
        "           s = re.sub(pattern, repl, s)\n",
        "      return s\n",
        "\n",
        "replacer = RegexpReplacer()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnsvEeCpiWNY"
      },
      "source": [
        "tokenized_abstract = []\n",
        "cleaned_abstract = []\n",
        "tokenized_title = []\n",
        "for abstract in df['abstract_fr'] :\n",
        "  tokenized_abstract.append((tokenizer.tokenize(replacer.replace(abstract.lower()))))\n",
        "  cleaned_abstract.append(replacer.replace(abstract.lower()))\n",
        "\n",
        "for title in df['titre']:\n",
        "  tokenized_title.append((tokenizer.tokenize(replacer.replace(title.lower()))))\n",
        "\n",
        "df['tokenized_abstract'] = tokenized_abstract\n",
        "df['cleaned_abstract'] = cleaned_abstract\n",
        "df['titre'] = tokenized_title"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "XwXnqbQDjwwE",
        "outputId": "b064d693-a215-430c-e0a3-05f7c17fe65d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>abstract_fr</th>\n",
              "      <th>keywords_fr</th>\n",
              "      <th>intro</th>\n",
              "      <th>titre</th>\n",
              "      <th>date</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>cleaned_abstract</th>\n",
              "      <th>new_keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous considérons dans notre travail la tâche ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Le modèle de la Grammaire Applicative et Cogn...</td>\n",
              "      <td>[éléments, de, conception, de, un, système, de...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[nous, considérons, dans, notre, travail, la, ...</td>\n",
              "      <td>nous considérons dans notre travail la tâche ...</td>\n",
              "      <td>[relative, grande, vitesse]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Nous donnons ici un aperçu du logiciel DECID ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Dans le domaine de l'ingénierie linguistique ...</td>\n",
              "      <td>[informatisation, du, dictionnaire, explicatif...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[nous, donnons, ici, un, aperçu, du, logiciel,...</td>\n",
              "      <td>nous donnons ici un aperçu du logiciel decid ...</td>\n",
              "      <td>[logiciel, développé, geta, informatiser, réda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Diverses méthodes ont été proposées pour cons...</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>[construction, de, une, représentation, sémant...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[diverses, méthodes, ont, été, proposées, pour...</td>\n",
              "      <td>diverses méthodes ont été proposées pour cons...</td>\n",
              "      <td>[syntaxique, construction, représentation, sém...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Le terme de lambda-DRT désigne un ensemble de...</td>\n",
              "      <td>None</td>\n",
              "      <td>La « Théorie des Représentations Discursives ...</td>\n",
              "      <td>[systèmes, de, types, pour, la, lambda, drt, a...</td>\n",
              "      <td>1998</td>\n",
              "      <td>[le, terme, de, lambda, drt, désigne, un, ense...</td>\n",
              "      <td>le terme de lambda drt désigne un ensemble de...</td>\n",
              "      <td>[terme, lambda, ensemble, construire, mise, oe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans cet article, nous comparons deux modèles...</td>\n",
              "      <td>None</td>\n",
              "      <td>TAG est un formalisme initialement développé ...</td>\n",
              "      <td>[une, grammaire, tag, vue, comme, une, grammai...</td>\n",
              "      <td>1998</td>\n",
              "      <td>[dans, cet, article, nous, comparons, deux, mo...</td>\n",
              "      <td>dans cet article nous comparons deux modèles ...</td>\n",
              "      <td>[tag]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                       new_keywords\n",
              "0      0  ...                        [relative, grande, vitesse]\n",
              "1      1  ...  [logiciel, développé, geta, informatiser, réda...\n",
              "2      2  ...  [syntaxique, construction, représentation, sém...\n",
              "3      3  ...  [terme, lambda, ensemble, construire, mise, oe...\n",
              "4      4  ...                                              [tag]\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tSJkO0ph9Vm",
        "outputId": "f480f249-6063-4a4e-c1f0-f85faa713c79"
      },
      "source": [
        "common_word = pd.Series(' '.join(df['cleaned_abstract']).split()).value_counts()[:50]\n",
        "common_word"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "de             16766\n",
              "le              6506\n",
              "des             5036\n",
              "la              4953\n",
              "les             3866\n",
              "et              3802\n",
              "un              3296\n",
              "une             3175\n",
              "à               3166\n",
              "nous            3021\n",
              "en              2582\n",
              "dans            2363\n",
              "pour            2303\n",
              "sur             1878\n",
              "du              1598\n",
              "que             1490\n",
              "est             1324\n",
              "par             1191\n",
              "corpus          1074\n",
              "qui             1021\n",
              "cet              967\n",
              "article          955\n",
              "sont             821\n",
              "cette            739\n",
              "ces              714\n",
              "ce               704\n",
              "système          700\n",
              "automatique      672\n",
              "analyse          661\n",
              "au               643\n",
              "plus             603\n",
              "résultats        552\n",
              "présentons       538\n",
              "mots             533\n",
              "notre            514\n",
              "méthode          510\n",
              "avec             476\n",
              "approche         472\n",
              "ou               460\n",
              "il               449\n",
              "a                441\n",
              "deux             426\n",
              "entre            426\n",
              "français         421\n",
              "partir           417\n",
              "textes           412\n",
              "données          386\n",
              "proposons        383\n",
              "langue           372\n",
              "modèle           362\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgDycpx1kBld",
        "outputId": "f0c72622-8e33-414e-cfd8-ca2d795c08d1"
      },
      "source": [
        "from string import digits\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('french')\n",
        "lemmatizer_output=WordNetLemmatizer()\n",
        "for index in range(len(df['tokenized_abstract'])) :\n",
        "  df['tokenized_abstract'][index] = [lemmatizer_output.lemmatize(word.lower(), pos='v') for word in df['tokenized_abstract'][index] if word not in common_word] \n",
        "  df['tokenized_abstract'][index] = [lemmatizer_output.lemmatize(word.lower(), pos='v') for word in df['tokenized_abstract'][index] if word not in stopwords]\n",
        "\n",
        "\n",
        "for index in range(len(df['titre'])) :\n",
        "  df['titre'][index] = [lemmatizer_output.lemmatize(word.lower(), pos='v') for word in df['titre'][index] if word not in stopwords] "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSY60srpkzdD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3626e4da-90bd-46dc-85b7-657f78f1a540"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>abstract_fr</th>\n",
              "      <th>keywords_fr</th>\n",
              "      <th>intro</th>\n",
              "      <th>titre</th>\n",
              "      <th>date</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>cleaned_abstract</th>\n",
              "      <th>new_keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous considérons dans notre travail la tâche ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Le modèle de la Grammaire Applicative et Cogn...</td>\n",
              "      <td>[éléments, conception, système, interprétation...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[considérons, travail, tâche, traitement, visa...</td>\n",
              "      <td>nous considérons dans notre travail la tâche ...</td>\n",
              "      <td>[relative, grande, vitesse]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Nous donnons ici un aperçu du logiciel DECID ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Dans le domaine de l'ingénierie linguistique ...</td>\n",
              "      <td>[informatisation, dictionnaire, explicatif, co...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[donnons, ici, aperçu, logiciel, decid, dévelo...</td>\n",
              "      <td>nous donnons ici un aperçu du logiciel decid ...</td>\n",
              "      <td>[logiciel, développé, geta, informatiser, réda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Diverses méthodes ont été proposées pour cons...</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>[construction, représentation, sémantique, gra...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[diverses, méthodes, proposées, construire, gr...</td>\n",
              "      <td>diverses méthodes ont été proposées pour cons...</td>\n",
              "      <td>[syntaxique, construction, représentation, sém...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Le terme de lambda-DRT désigne un ensemble de...</td>\n",
              "      <td>None</td>\n",
              "      <td>La « Théorie des Représentations Discursives ...</td>\n",
              "      <td>[systèmes, type, lambda, drt, ascendante]</td>\n",
              "      <td>1998</td>\n",
              "      <td>[terme, lambda, drt, désigne, ensemble, méthod...</td>\n",
              "      <td>le terme de lambda drt désigne un ensemble de...</td>\n",
              "      <td>[terme, lambda, ensemble, construire, mise, oe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans cet article, nous comparons deux modèles...</td>\n",
              "      <td>None</td>\n",
              "      <td>TAG est un formalisme initialement développé ...</td>\n",
              "      <td>[grammaire, tag, vue, comme, grammaire, sens, ...</td>\n",
              "      <td>1998</td>\n",
              "      <td>[comparons, modèles, linguistiques, utilisés, ...</td>\n",
              "      <td>dans cet article nous comparons deux modèles ...</td>\n",
              "      <td>[tag]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                       new_keywords\n",
              "0      0  ...                        [relative, grande, vitesse]\n",
              "1      1  ...  [logiciel, développé, geta, informatiser, réda...\n",
              "2      2  ...  [syntaxique, construction, représentation, sém...\n",
              "3      3  ...  [terme, lambda, ensemble, construire, mise, oe...\n",
              "4      4  ...                                              [tag]\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNxhrryaiSGc",
        "outputId": "991d2408-60b5-4583-9e41-21f789db6806"
      },
      "source": [
        "# Ici nous supprimons les lignes n'ayant ni abstract ni keyword\n",
        "\n",
        "num_line = []\n",
        "for index in range(0, len(df)):\n",
        "  if (df['abstract_fr'][index] == 'None' or df['abstract_fr'][index] == ' ') and df['keywords_fr'][index] == 'None':\n",
        "    num_line.append(index)\n",
        "\n",
        "print(num_line)\n",
        "num_line.append(1545)\n",
        "df = df.drop(num_line)\n",
        "df.reset_index(inplace = True)\n",
        "len(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17, 20, 25, 26, 27, 30, 43, 47, 49, 51, 53, 56, 58, 66, 67, 68, 70, 71, 81, 82, 83, 84, 122, 137, 193, 254, 333, 637, 686, 737, 802, 818, 833, 834, 845, 931, 932, 933, 936, 937, 938, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 952, 953, 1205, 1291, 1292]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXFP26H8b7fu"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "list_useless = ['algorithme', 'qui', 'que', 'selon', 'mais', 'texte', 'aperçu', 'textes', 'afin', 'donc', 'travail', 'tâche', 'cependant', 'alors', 'droite', 'gauche', 'sous', 'forme', 'partie', 'entre', 'partir', 'a', 'ici', 'plus', 'moins', 'exemple', 'analyse']\n",
        "for i in range (0,150) :\n",
        "  list_useless.append(str(i))\n",
        "\n",
        "new_keywords = []\n",
        "for index in range(0, len(df)):\n",
        "  keywords_list = []\n",
        "  cnt = Counter()\n",
        "  for mot in df['tokenized_abstract'][index]:\n",
        "    if len(mot) > 2:\n",
        "      if mot not in list_useless :\n",
        "        if mot[len(mot)-3] != 'o' and mot[len(mot)-2] != \"n\" and mot[len(mot)-1] != \"s\" :\n",
        "          if mot[len(mot)-3] != 'a' and mot[len(mot)-2] != \"i\" and mot[len(mot)-1] != \"t\" :\n",
        "            cnt[mot] += 1\n",
        "  #print(cnt)\n",
        "  #print(index)\n",
        "  if df['abstract_fr'][index] != 'None' :\n",
        "    word, max_count = cnt.most_common()[0]\n",
        "    for mot in df['tokenized_abstract'][index]:\n",
        "      if cnt[mot] == max_count and mot not in keywords_list:\n",
        "        keywords_list.append(mot)\n",
        "    if df['keywords_fr'][index] == None :\n",
        "      df['keywords_fr'][index] = keywords_list\n",
        "  new_keywords.append(keywords_list)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_od_g9lcvR8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "2757ec2d-9cd7-466c-dfe5-f0c6fd661da7"
      },
      "source": [
        "for index in range(0, len(df)):\n",
        "  keywords_list = []\n",
        "  if df['keywords_fr'][index] != 'None' :\n",
        "    keywords_list = str(df['keywords_fr'][index]).split(',')\n",
        "  new_keywords[index] = new_keywords[index] + keywords_list\n",
        "\n",
        "\n",
        "df['new_keywords'] = new_keywords\n",
        "df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>abstract_fr</th>\n",
              "      <th>keywords_fr</th>\n",
              "      <th>intro</th>\n",
              "      <th>titre</th>\n",
              "      <th>date</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "      <th>cleaned_abstract</th>\n",
              "      <th>new_keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous considérons dans notre travail la tâche ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Le modèle de la Grammaire Applicative et Cogn...</td>\n",
              "      <td>Éléments de conception d'un système d'interpr...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[considérons, travail, tâche, traitement, visa...</td>\n",
              "      <td>nous considérons dans notre travail la tâche ...</td>\n",
              "      <td>[relative, grande, vitesse]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Nous donnons ici un aperçu du logiciel DECID ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Dans le domaine de l'ingénierie linguistique ...</td>\n",
              "      <td>Informatisation du dictionnaire explicatif et...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[donnons, ici, aperçu, logiciel, decid, dévelo...</td>\n",
              "      <td>nous donnons ici un aperçu du logiciel decid ...</td>\n",
              "      <td>[logiciel, développé, geta, informatiser, réda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Diverses méthodes ont été proposées pour cons...</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>Construction d'une représentation sémantique ...</td>\n",
              "      <td>1997</td>\n",
              "      <td>[diverses, méthodes, proposées, construire, gr...</td>\n",
              "      <td>diverses méthodes ont été proposées pour cons...</td>\n",
              "      <td>[syntaxique, construction, représentation, sém...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Le terme de lambda-DRT désigne un ensemble de...</td>\n",
              "      <td>None</td>\n",
              "      <td>La « Théorie des Représentations Discursives ...</td>\n",
              "      <td>Systèmes de types pour la (lambda-)DRT ascend...</td>\n",
              "      <td>1998</td>\n",
              "      <td>[terme, lambda, drt, désigne, ensemble, méthod...</td>\n",
              "      <td>le terme de lambda drt désigne un ensemble de...</td>\n",
              "      <td>[terme, lambda, ensemble, construire, mise, oe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans cet article, nous comparons deux modèles...</td>\n",
              "      <td>None</td>\n",
              "      <td>TAG est un formalisme initialement développé ...</td>\n",
              "      <td>Une grammaire TAG vue comme une grammaire Sen...</td>\n",
              "      <td>1998</td>\n",
              "      <td>[comparons, modèles, linguistiques, utilisés, ...</td>\n",
              "      <td>dans cet article nous comparons deux modèles ...</td>\n",
              "      <td>[tag]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1539</th>\n",
              "      <td>1597</td>\n",
              "      <td>Dans cet article, nous présentons une approch...</td>\n",
              "      <td>Curriculum d'apprentissage, transfert d'appre...</td>\n",
              "      <td>L'apprentissage humain est réalisé par étapes...</td>\n",
              "      <td>Curriculum d'apprentissage : reconnaissance d...</td>\n",
              "      <td>2019</td>\n",
              "      <td>[bout, bout, extraction, concepts, sémantiques...</td>\n",
              "      <td>dans cet article nous présentons une approche...</td>\n",
              "      <td>[extraction, particulier, pilotée, curriculum,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1540</th>\n",
              "      <td>1598</td>\n",
              "      <td>Cet article présente une méthodologie de déte...</td>\n",
              "      <td>ellipse, anglais, corpus, sous-titres, détect...</td>\n",
              "      <td>L'ellipse renvoie à une incomplétude syntaxiq...</td>\n",
              "      <td>Détection des ellipses dans des corpus de sou...</td>\n",
              "      <td>2019</td>\n",
              "      <td>[présente, méthodologie, détection, ellipses, ...</td>\n",
              "      <td>cet article présente une méthodologie de déte...</td>\n",
              "      <td>[présente, détection, étiquette, morphosyntaxi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1541</th>\n",
              "      <td>1599</td>\n",
              "      <td>La génération automatique de poésie est une t...</td>\n",
              "      <td>génération de poésie, réseaux de neurones, fa...</td>\n",
              "      <td>La génération automatique de poésie est une t...</td>\n",
              "      <td>La génération automatique de poésie en français</td>\n",
              "      <td>2019</td>\n",
              "      <td>[génération, poésie, tâche, ardue, informatiqu...</td>\n",
              "      <td>la génération automatique de poésie est une t...</td>\n",
              "      <td>[génération,  génération de poésie,  réseaux d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1542</th>\n",
              "      <td>1600</td>\n",
              "      <td>Nous proposons une architecture neuronale ave...</td>\n",
              "      <td>Réseaux neuronaux, modélisation de séquences,...</td>\n",
              "      <td>L'étiquetage de séquences est un problème imp...</td>\n",
              "      <td>Modèles neuronaux hybrides pour la modélisati...</td>\n",
              "      <td>2019</td>\n",
              "      <td>[architecture, neuronale, caractéristiques, pr...</td>\n",
              "      <td>nous proposons une architecture neuronale ave...</td>\n",
              "      <td>[architecture,  Réseaux neuronaux,  modélisati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1543</th>\n",
              "      <td>1601</td>\n",
              "      <td>Nous présentons la base PolylexFLE, contenant...</td>\n",
              "      <td>expressions polylexicales vebales, niveau CEC...</td>\n",
              "      <td>Les expressions polylexicales (EP) constituen...</td>\n",
              "      <td>PolylexFLE : une base de données d'expression...</td>\n",
              "      <td>2019</td>\n",
              "      <td>[base, polylexfle, contenant, 4295, expression...</td>\n",
              "      <td>nous présentons la base polylexfle contenant ...</td>\n",
              "      <td>[cecr,  expressions polylexicales vebales,  ni...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1544 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ...                                       new_keywords\n",
              "0         0  ...                        [relative, grande, vitesse]\n",
              "1         1  ...  [logiciel, développé, geta, informatiser, réda...\n",
              "2         2  ...  [syntaxique, construction, représentation, sém...\n",
              "3         3  ...  [terme, lambda, ensemble, construire, mise, oe...\n",
              "4         4  ...                                              [tag]\n",
              "...     ...  ...                                                ...\n",
              "1539   1597  ...  [extraction, particulier, pilotée, curriculum,...\n",
              "1540   1598  ...  [présente, détection, étiquette, morphosyntaxi...\n",
              "1541   1599  ...  [génération,  génération de poésie,  réseaux d...\n",
              "1542   1600  ...  [architecture,  Réseaux neuronaux,  modélisati...\n",
              "1543   1601  ...  [cecr,  expressions polylexicales vebales,  ni...\n",
              "\n",
              "[1544 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUFDCvtePJsG"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl2dViaIrdBa"
      },
      "source": [
        "#liste de tous les keywords du dataframe\n",
        "list_keywords = []\n",
        "for i in range(len(df)):\n",
        "  if df.new_keywords[i] != \"None\":\n",
        "    list_keywords.append(df.new_keywords[i])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcHT1qrtWTs6"
      },
      "source": [
        "for i in range (1544):\r\n",
        "  string=\"\"\r\n",
        "  for j in range (len(list_keywords[i])):\r\n",
        "    string = string + str(list_keywords[i][j])\r\n",
        "  list_keywords[i] = string"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvihjws2qZc0",
        "outputId": "03b8ac62-cf41-4285-cc65-c3761e12d331"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# tfidf vectorizer de la librairies sklearn\n",
        "vectorizer = TfidfVectorizer(stop_words=stopwords,max_features=1000, max_df = 0.5, use_idf = True, ngram_range=(1,3))\n",
        "X = vectorizer.fit_transform(list_keywords)\n",
        "print(X.shape)\n",
        "\n",
        "terms = vectorizer.get_feature_names()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1544, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ouDk61_wB05"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#clustering\n",
        "num_clusters = 9\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "km.fit(X)\n",
        "clusters = km.labels_.tolist()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgGWY915SMvE",
        "outputId": "33acda34-575f-4a5e-b2ab-55ba48220c88"
      },
      "source": [
        "X_dist = km.transform(X)\r\n",
        "X_dist"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4104544 , 0.30342233, 0.38876464, ..., 0.48346403, 0.4378116 ,\n",
              "        0.34011296],\n",
              "       [0.4104544 , 0.30342233, 0.38876464, ..., 0.48346403, 0.4378116 ,\n",
              "        0.34011296],\n",
              "       [0.4104544 , 0.30342233, 0.38876464, ..., 0.48346403, 0.4378116 ,\n",
              "        0.34011296],\n",
              "       ...,\n",
              "       [1.07064537, 1.02986863, 1.06141981, ..., 1.10029006, 1.06789043,\n",
              "        1.04106714],\n",
              "       [1.07494281, 1.03555331, 1.07052281, ..., 1.1028466 , 1.08636092,\n",
              "        1.05269381],\n",
              "       [1.08095921, 1.04174184, 1.07291097, ..., 1.10904978, 1.09018082,\n",
              "        1.05570022]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "BYP5o47BZSQX",
        "outputId": "4bef39b2-f3ac-41d4-a072-edb4373141cb"
      },
      "source": [
        "centroid = []\r\n",
        "for i in range (1544):\r\n",
        "  centroid.append(list(X_dist[i]))\r\n",
        "\r\n",
        "df_cluster= pd.DataFrame.from_records(centroid)\r\n",
        "df_cluster"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.410454</td>\n",
              "      <td>0.303422</td>\n",
              "      <td>0.388765</td>\n",
              "      <td>0.417268</td>\n",
              "      <td>0.502902</td>\n",
              "      <td>0.124486</td>\n",
              "      <td>0.483464</td>\n",
              "      <td>0.437812</td>\n",
              "      <td>0.340113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.410454</td>\n",
              "      <td>0.303422</td>\n",
              "      <td>0.388765</td>\n",
              "      <td>0.417268</td>\n",
              "      <td>0.502902</td>\n",
              "      <td>0.124486</td>\n",
              "      <td>0.483464</td>\n",
              "      <td>0.437812</td>\n",
              "      <td>0.340113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.410454</td>\n",
              "      <td>0.303422</td>\n",
              "      <td>0.388765</td>\n",
              "      <td>0.417268</td>\n",
              "      <td>0.502902</td>\n",
              "      <td>0.124486</td>\n",
              "      <td>0.483464</td>\n",
              "      <td>0.437812</td>\n",
              "      <td>0.340113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.410454</td>\n",
              "      <td>0.303422</td>\n",
              "      <td>0.388765</td>\n",
              "      <td>0.417268</td>\n",
              "      <td>0.502902</td>\n",
              "      <td>0.124486</td>\n",
              "      <td>0.483464</td>\n",
              "      <td>0.437812</td>\n",
              "      <td>0.340113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.080959</td>\n",
              "      <td>1.045019</td>\n",
              "      <td>1.059204</td>\n",
              "      <td>1.083565</td>\n",
              "      <td>1.119335</td>\n",
              "      <td>1.001387</td>\n",
              "      <td>1.108149</td>\n",
              "      <td>1.091641</td>\n",
              "      <td>1.052836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1539</th>\n",
              "      <td>1.074833</td>\n",
              "      <td>1.039027</td>\n",
              "      <td>1.062911</td>\n",
              "      <td>1.042678</td>\n",
              "      <td>0.928391</td>\n",
              "      <td>0.992530</td>\n",
              "      <td>1.101802</td>\n",
              "      <td>1.087877</td>\n",
              "      <td>1.045485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1540</th>\n",
              "      <td>1.071826</td>\n",
              "      <td>1.027287</td>\n",
              "      <td>1.056932</td>\n",
              "      <td>1.062996</td>\n",
              "      <td>1.098992</td>\n",
              "      <td>0.985449</td>\n",
              "      <td>1.063282</td>\n",
              "      <td>1.065703</td>\n",
              "      <td>1.047508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1541</th>\n",
              "      <td>1.070645</td>\n",
              "      <td>1.029869</td>\n",
              "      <td>1.061420</td>\n",
              "      <td>1.072894</td>\n",
              "      <td>1.110402</td>\n",
              "      <td>0.989510</td>\n",
              "      <td>1.100290</td>\n",
              "      <td>1.067890</td>\n",
              "      <td>1.041067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1542</th>\n",
              "      <td>1.074943</td>\n",
              "      <td>1.035553</td>\n",
              "      <td>1.070523</td>\n",
              "      <td>1.078198</td>\n",
              "      <td>1.114519</td>\n",
              "      <td>0.998397</td>\n",
              "      <td>1.102847</td>\n",
              "      <td>1.086361</td>\n",
              "      <td>1.052694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1543</th>\n",
              "      <td>1.080959</td>\n",
              "      <td>1.041742</td>\n",
              "      <td>1.072911</td>\n",
              "      <td>1.079348</td>\n",
              "      <td>1.119335</td>\n",
              "      <td>0.996166</td>\n",
              "      <td>1.109050</td>\n",
              "      <td>1.090181</td>\n",
              "      <td>1.055700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1544 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2  ...         6         7         8\n",
              "0     0.410454  0.303422  0.388765  ...  0.483464  0.437812  0.340113\n",
              "1     0.410454  0.303422  0.388765  ...  0.483464  0.437812  0.340113\n",
              "2     0.410454  0.303422  0.388765  ...  0.483464  0.437812  0.340113\n",
              "3     0.410454  0.303422  0.388765  ...  0.483464  0.437812  0.340113\n",
              "4     1.080959  1.045019  1.059204  ...  1.108149  1.091641  1.052836\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "1539  1.074833  1.039027  1.062911  ...  1.101802  1.087877  1.045485\n",
              "1540  1.071826  1.027287  1.056932  ...  1.063282  1.065703  1.047508\n",
              "1541  1.070645  1.029869  1.061420  ...  1.100290  1.067890  1.041067\n",
              "1542  1.074943  1.035553  1.070523  ...  1.102847  1.086361  1.052694\n",
              "1543  1.080959  1.041742  1.072911  ...  1.109050  1.090181  1.055700\n",
              "\n",
              "[1544 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_8wpQzvO5X9"
      },
      "source": [
        "# Préprocessing \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMppbA9uKLgE"
      },
      "source": [
        "## Préprocessing sur les keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-pUT_hKOGLd"
      },
      "source": [
        "Tout d’abord nous stockons toutes nos dates dans y :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ECyRZEVHTAw",
        "outputId": "e391ca32-4858-4ece-b79d-68135778fce4"
      },
      "source": [
        "y = df['date']\r\n",
        "y"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1997\n",
              "1       1997\n",
              "2       1997\n",
              "3       1998\n",
              "4       1998\n",
              "        ... \n",
              "1539    2019\n",
              "1540    2019\n",
              "1541    2019\n",
              "1542    2019\n",
              "1543    2019\n",
              "Name: date, Length: 1544, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUMkIIl2OaBr"
      },
      "source": [
        "Puis nous stockons une unique occurence de nos mots clefs dans une liste appelée data :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNTip2yxLtR4",
        "outputId": "688a92fc-16c0-4866-844d-49a36328f088"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "# define example\r\n",
        "keywords = df['new_keywords']\r\n",
        "data = []\r\n",
        "for i in range (0, len(keywords)):\r\n",
        "  for j in range (0, len(keywords[i])):\r\n",
        "    if keywords[i][j] not in data:\r\n",
        "      data.append(keywords[i][j])\r\n",
        "values = np.array(data)\r\n",
        "print(values)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['relative' 'grande' 'vitesse' ... ' expressions polylexicales vebales'\n",
            " ' niveau CECR' ' TAL pour la didactique du FLE. ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr_Ag3VxOgrw"
      },
      "source": [
        "Nous stockons dans x au format Dataframe nos keywords (ceux générés précédemment et ceux déjà existants) et nous créons pour chaque mot clef présent dans data une colonne dans x qui lui sera associée. Ces colonnes ne contiennent d’abord que des 0 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne0SKMTcPZIx"
      },
      "source": [
        "x = df['new_keywords']\r\n",
        "x = x.to_frame()\r\n",
        "column_values = [0 for i in range(0,len(x))]\r\n",
        "for i in range(0,len(data)) :\r\n",
        "  column_name = 'keyword' +str(i)\r\n",
        "  x[column_name] = column_values"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOJjB7lzOmsY"
      },
      "source": [
        "Puis nous remplissons ces colonnes à la manière d'un one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1aImNdsPSCX",
        "outputId": "aff16272-4c2c-432d-e326-4cdc97861f38"
      },
      "source": [
        "for i in range(0,1544):\r\n",
        "  for j in range (0, len(keywords[i])):\r\n",
        "    for k in range (0, len(data)):\r\n",
        "      column_name = \"keyword\" + str(k)\r\n",
        "      if keywords[i][j] == data[k]:\r\n",
        "        x[column_name][i] = 1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex5NB2X3POsZ"
      },
      "source": [
        "On supprime alors la première colonne qui contenait la liste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "4LTI5qtIbxwg",
        "outputId": "afe2477d-8436-40e7-e6d9-0ea338c5660b"
      },
      "source": [
        "x = x.drop(\"new_keywords\",axis = 1)\r\n",
        "x.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword0</th>\n",
              "      <th>keyword1</th>\n",
              "      <th>keyword2</th>\n",
              "      <th>keyword3</th>\n",
              "      <th>keyword4</th>\n",
              "      <th>keyword5</th>\n",
              "      <th>keyword6</th>\n",
              "      <th>keyword7</th>\n",
              "      <th>keyword8</th>\n",
              "      <th>keyword9</th>\n",
              "      <th>keyword10</th>\n",
              "      <th>keyword11</th>\n",
              "      <th>keyword12</th>\n",
              "      <th>keyword13</th>\n",
              "      <th>keyword14</th>\n",
              "      <th>keyword15</th>\n",
              "      <th>keyword16</th>\n",
              "      <th>keyword17</th>\n",
              "      <th>keyword18</th>\n",
              "      <th>keyword19</th>\n",
              "      <th>keyword20</th>\n",
              "      <th>keyword21</th>\n",
              "      <th>keyword22</th>\n",
              "      <th>keyword23</th>\n",
              "      <th>keyword24</th>\n",
              "      <th>keyword25</th>\n",
              "      <th>keyword26</th>\n",
              "      <th>keyword27</th>\n",
              "      <th>keyword28</th>\n",
              "      <th>keyword29</th>\n",
              "      <th>keyword30</th>\n",
              "      <th>keyword31</th>\n",
              "      <th>keyword32</th>\n",
              "      <th>keyword33</th>\n",
              "      <th>keyword34</th>\n",
              "      <th>keyword35</th>\n",
              "      <th>keyword36</th>\n",
              "      <th>keyword37</th>\n",
              "      <th>keyword38</th>\n",
              "      <th>keyword39</th>\n",
              "      <th>...</th>\n",
              "      <th>keyword5819</th>\n",
              "      <th>keyword5820</th>\n",
              "      <th>keyword5821</th>\n",
              "      <th>keyword5822</th>\n",
              "      <th>keyword5823</th>\n",
              "      <th>keyword5824</th>\n",
              "      <th>keyword5825</th>\n",
              "      <th>keyword5826</th>\n",
              "      <th>keyword5827</th>\n",
              "      <th>keyword5828</th>\n",
              "      <th>keyword5829</th>\n",
              "      <th>keyword5830</th>\n",
              "      <th>keyword5831</th>\n",
              "      <th>keyword5832</th>\n",
              "      <th>keyword5833</th>\n",
              "      <th>keyword5834</th>\n",
              "      <th>keyword5835</th>\n",
              "      <th>keyword5836</th>\n",
              "      <th>keyword5837</th>\n",
              "      <th>keyword5838</th>\n",
              "      <th>keyword5839</th>\n",
              "      <th>keyword5840</th>\n",
              "      <th>keyword5841</th>\n",
              "      <th>keyword5842</th>\n",
              "      <th>keyword5843</th>\n",
              "      <th>keyword5844</th>\n",
              "      <th>keyword5845</th>\n",
              "      <th>keyword5846</th>\n",
              "      <th>keyword5847</th>\n",
              "      <th>keyword5848</th>\n",
              "      <th>keyword5849</th>\n",
              "      <th>keyword5850</th>\n",
              "      <th>keyword5851</th>\n",
              "      <th>keyword5852</th>\n",
              "      <th>keyword5853</th>\n",
              "      <th>keyword5854</th>\n",
              "      <th>keyword5855</th>\n",
              "      <th>keyword5856</th>\n",
              "      <th>keyword5857</th>\n",
              "      <th>keyword5858</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5859 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   keyword0  keyword1  keyword2  ...  keyword5856  keyword5857  keyword5858\n",
              "0         1         1         1  ...            0            0            0\n",
              "1         0         0         0  ...            0            0            0\n",
              "2         0         0         0  ...            0            0            0\n",
              "3         0         0         0  ...            0            0            0\n",
              "4         0         0         0  ...            0            0            0\n",
              "\n",
              "[5 rows x 5859 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJFvjMP0NuyB"
      },
      "source": [
        "## Préprocessing sur les titres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIwTIfUSIPjo",
        "outputId": "60c97adf-258a-46a8-b48e-190e201fe976"
      },
      "source": [
        "titre = df['titre']\r\n",
        "data2 = []\r\n",
        "for i in range (0, len(titre)):\r\n",
        "  for j in range (0, len(titre[i])):\r\n",
        "    if titre[i][j] not in data2:\r\n",
        "      data2.append(titre[i][j])\r\n",
        "values2 = np.array(data2)\r\n",
        "print(values2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['éléments' 'conception' 'système' ... 'poésie' 'meilleur' 'polylexfle']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hTYm-RsHf5n"
      },
      "source": [
        "x2 = df['titre']\r\n",
        "x2 = x2.to_frame()\r\n",
        "column_values = [0 for i in range(0,len(x2))]\r\n",
        "for i in range(0,len(data2)) :\r\n",
        "  column_name = 'titre' +str(i)\r\n",
        "  x2[column_name] = column_values"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EAk8zu0JU1k",
        "outputId": "2fc4c6af-e9c0-4960-bf88-ea707b27bd56"
      },
      "source": [
        "for i in range(0,1544):\r\n",
        "  for j in range (0, len(titre[i])):\r\n",
        "    for k in range (0, len(data2)):\r\n",
        "      column_name = \"titre\" + str(k)\r\n",
        "      if titre[i][j] == data2[k]:\r\n",
        "        x2[column_name][i] = 1"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Rms5WZohJTlC",
        "outputId": "9ebce36a-f069-495b-cf80-2a96005adbcd"
      },
      "source": [
        "x2 = x2.drop(\"titre\",axis = 1)\r\n",
        "x2.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titre0</th>\n",
              "      <th>titre1</th>\n",
              "      <th>titre2</th>\n",
              "      <th>titre3</th>\n",
              "      <th>titre4</th>\n",
              "      <th>titre5</th>\n",
              "      <th>titre6</th>\n",
              "      <th>titre7</th>\n",
              "      <th>titre8</th>\n",
              "      <th>titre9</th>\n",
              "      <th>titre10</th>\n",
              "      <th>titre11</th>\n",
              "      <th>titre12</th>\n",
              "      <th>titre13</th>\n",
              "      <th>titre14</th>\n",
              "      <th>titre15</th>\n",
              "      <th>titre16</th>\n",
              "      <th>titre17</th>\n",
              "      <th>titre18</th>\n",
              "      <th>titre19</th>\n",
              "      <th>titre20</th>\n",
              "      <th>titre21</th>\n",
              "      <th>titre22</th>\n",
              "      <th>titre23</th>\n",
              "      <th>titre24</th>\n",
              "      <th>titre25</th>\n",
              "      <th>titre26</th>\n",
              "      <th>titre27</th>\n",
              "      <th>titre28</th>\n",
              "      <th>titre29</th>\n",
              "      <th>titre30</th>\n",
              "      <th>titre31</th>\n",
              "      <th>titre32</th>\n",
              "      <th>titre33</th>\n",
              "      <th>titre34</th>\n",
              "      <th>titre35</th>\n",
              "      <th>titre36</th>\n",
              "      <th>titre37</th>\n",
              "      <th>titre38</th>\n",
              "      <th>titre39</th>\n",
              "      <th>...</th>\n",
              "      <th>titre62</th>\n",
              "      <th>titre63</th>\n",
              "      <th>titre64</th>\n",
              "      <th>titre65</th>\n",
              "      <th>titre66</th>\n",
              "      <th>titre67</th>\n",
              "      <th>titre68</th>\n",
              "      <th>titre69</th>\n",
              "      <th>titre70</th>\n",
              "      <th>titre71</th>\n",
              "      <th>titre72</th>\n",
              "      <th>titre73</th>\n",
              "      <th>titre74</th>\n",
              "      <th>titre75</th>\n",
              "      <th>titre76</th>\n",
              "      <th>titre77</th>\n",
              "      <th>titre78</th>\n",
              "      <th>titre79</th>\n",
              "      <th>titre80</th>\n",
              "      <th>titre81</th>\n",
              "      <th>titre82</th>\n",
              "      <th>titre83</th>\n",
              "      <th>titre84</th>\n",
              "      <th>titre85</th>\n",
              "      <th>titre86</th>\n",
              "      <th>titre87</th>\n",
              "      <th>titre88</th>\n",
              "      <th>titre89</th>\n",
              "      <th>titre90</th>\n",
              "      <th>titre91</th>\n",
              "      <th>titre92</th>\n",
              "      <th>titre93</th>\n",
              "      <th>titre94</th>\n",
              "      <th>titre95</th>\n",
              "      <th>titre96</th>\n",
              "      <th>titre97</th>\n",
              "      <th>titre98</th>\n",
              "      <th>titre99</th>\n",
              "      <th>titre100</th>\n",
              "      <th>titre101</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   titre0  titre1  titre2  titre3  ...  titre98  titre99  titre100  titre101\n",
              "0       1       1       1       1  ...        0        0         0         0\n",
              "1       1       0       1       0  ...        0        0         0         0\n",
              "2       1       0       1       1  ...        0        0         0         0\n",
              "3       1       0       1       0  ...        0        0         0         0\n",
              "4       1       0       1       1  ...        0        0         0         0\n",
              "\n",
              "[5 rows x 102 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY6P2iVBNiav"
      },
      "source": [
        "## Séparation du dataset en un train set, test set et un validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0jgmzW2PuME"
      },
      "source": [
        "Enfin, nous séparons notre x et notre y en train et test avec une proportion de 80% - 20% à l'aide de train_test_split de sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g3UNU_uMK-G",
        "outputId": "3ce7f0b0-1618-4093-be7d-d1bdfbe6ae4e"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)\r\n",
        "\r\n",
        "print(\"Dimension x_train :\", x_train.shape)\r\n",
        "print(\"Dimension of y_train :\", y_train.shape)\r\n",
        "print(\"Dimension of x_test :\", x_test.shape)\r\n",
        "print(\"Dimension of y_test :\", y_test.shape)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension x_train : (1235, 5859)\n",
            "Dimension of y_train : (1235,)\n",
            "Dimension of x_test : (309, 5859)\n",
            "Dimension of y_test : (309,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XBMIGbwQj1A"
      },
      "source": [
        "Puis nous divisons le x_test et le y_test en deux avec une proportion de 50% - 50% dans test et valid. Nous avons donc la répartition attendue :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqPSW3wB2o1G",
        "outputId": "57b50a7a-5114-4df9-f87c-015795c65477"
      },
      "source": [
        "x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, test_size = 0.50, random_state = 0)\r\n",
        "\r\n",
        "print(\"Dimension of x_test :\", x_test.shape)\r\n",
        "print(\"Dimension of y_test :\", y_test.shape)\r\n",
        "print(\"Dimension of x_valid :\", x_valid.shape)\r\n",
        "print(\"Dimension of y_valid :\", y_valid.shape)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of x_test : (154, 5859)\n",
            "Dimension of y_test : (154,)\n",
            "Dimension of x_valid : (155, 5859)\n",
            "Dimension of y_valid : (155,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyhvTGNq5PeR"
      },
      "source": [
        "y_traind, y_testd, y_validd = y_train.to_frame(), y_test.to_frame(), y_valid.to_frame()"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7kukF8yOoGv"
      },
      "source": [
        "Vérification que les dates sont relativements bien séparées de façons égales entre les 3 set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_nLn7S24AwM",
        "outputId": "6bb21822-c2a5-42c9-be74-c2129dc6a28e"
      },
      "source": [
        "date_train=[]\r\n",
        "date_valid=[]\r\n",
        "date_test =[]\r\n",
        "\r\n",
        "for i in range(1235):\r\n",
        "  if y_traind.iloc[i,0] not in date_train :\r\n",
        "    date_train.append (y_traind.iloc[i,0])\r\n",
        "date_train.sort()\r\n",
        "print(date_train)\r\n",
        "\r\n",
        "for i in range(155):\r\n",
        "  if y_validd.iloc[i,0] not in date_valid :\r\n",
        "    date_valid.append (y_validd.iloc[i,0])\r\n",
        "date_valid.sort()\r\n",
        "print(date_valid)\r\n",
        "\r\n",
        "for i in range(154):\r\n",
        "  if y_testd.iloc[i,0] not in date_test :\r\n",
        "    date_test.append (y_testd.iloc[i,0])\r\n",
        "date_test.sort()\r\n",
        "print(date_test)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
            "['1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
            "['1998', '1999', '2000', '2001', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2018', '2019']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ3nJ2g7O4E6"
      },
      "source": [
        "Sachant que certaines dates n'apparraissent que quelques fois dans le dataset préprocessé la répartition est plutot bonne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBoYFbYqPZFi"
      },
      "source": [
        "Même procédé pour les titres et les distances aux centroid des clusters\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0EIJ95TPMry"
      },
      "source": [
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y, test_size = 0.20, random_state = 0)\r\n",
        "x_test2, x_valid2, y_test2, y_valid2 = train_test_split(x_test2, y_test2, test_size = 0.50, random_state = 0)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvcXJGMdcBjn"
      },
      "source": [
        "x_train3, x_test3, y_train3, y_test3 = train_test_split(df_cluster, y, test_size = 0.20, random_state = 0)\r\n",
        "x_test3, x_valid3, y_test3, y_valid3 = train_test_split(x_test3, y_test3, test_size = 0.50, random_state = 0)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-bLfU1undvP"
      },
      "source": [
        "# Modèles et prédictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10kXfxIxPYXi"
      },
      "source": [
        "## RandomForestClassifier sur les keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNHicu1nQvhr"
      },
      "source": [
        "Il est important de noter que l’accuracy n’est pas une métrique représentative dans notre cas, en effet, une erreur d’un an est tout à fait acceptable. Nous regardons donc aussi la MSE comme valeur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3tDKQM9Mvvp",
        "outputId": "91cecdd1-21e8-4741-eb9b-5acd6c4243dc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "model1 = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "model1.fit(x_train, y_train)\r\n",
        "\r\n",
        "y_pred1 = model1.predict(x_valid)\r\n",
        "\r\n",
        "\r\n",
        "print(\"Training Accuracy :\", model1.score(x_train, y_train))\r\n",
        "print(\"Validating Accuracy :\", model1.score(x_valid, y_valid))\r\n",
        "print(\"MSE :\", mean_squared_error(y_validd, y_pred1))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy : 0.9959514170040485\n",
            "Validating Accuracy : 0.08387096774193549\n",
            "MSE : 80.06451612903226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed-NJ8io4oqj",
        "outputId": "35dfa042-5a1c-441c-b202-0ae6ebf44c06"
      },
      "source": [
        "y_valid_list = y_validd['date'].to_numpy()\r\n",
        "y_valid_list"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2015', '2015', '2006', '2009', '2004', '2005', '2013', '2006',\n",
              "       '2009', '2003', '2013', '2003', '2013', '2005', '2005', '2002',\n",
              "       '2011', '2014', '2013', '2001', '2006', '2010', '2003', '2002',\n",
              "       '2014', '2009', '2010', '2008', '2007', '2002', '1999', '2008',\n",
              "       '2003', '2002', '2007', '2016', '2015', '2015', '2007', '2011',\n",
              "       '2017', '2016', '2012', '2001', '2006', '2007', '2006', '2005',\n",
              "       '2015', '2009', '2013', '2010', '2017', '2009', '2003', '2010',\n",
              "       '2018', '2015', '2006', '2013', '1998', '2018', '2001', '2012',\n",
              "       '2012', '2008', '2013', '2015', '2007', '2006', '2009', '2014',\n",
              "       '2009', '2005', '2015', '2005', '2012', '2013', '2013', '2013',\n",
              "       '2016', '2017', '2006', '1997', '2012', '2003', '1999', '2000',\n",
              "       '2002', '2019', '2017', '2010', '2017', '2001', '2001', '2000',\n",
              "       '2012', '2004', '2014', '2007', '2009', '2008', '2005', '2007',\n",
              "       '2012', '2009', '2006', '1999', '2004', '2019', '2015', '2002',\n",
              "       '1999', '2016', '2009', '2014', '2001', '2016', '2010', '2012',\n",
              "       '2015', '2018', '2008', '2003', '2017', '2015', '2014', '2013',\n",
              "       '2010', '2007', '2015', '2009', '2004', '2016', '2001', '2007',\n",
              "       '2018', '2011', '2017', '1999', '2007', '2010', '2008', '2010',\n",
              "       '2004', '2002', '2003', '2016', '1997', '2005', '2009', '2009',\n",
              "       '2016', '2008', '2007'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VFoPcB7Q1F1"
      },
      "source": [
        "Nous avons créée une nouvelle métrique qui nous est propre. On obtient alors la proportion de date bien prédite à un seuil de tolérance près. Elle prend en argument le seuil de tolérance (nombre d’année en valeur absolue acceptable) ainsi que les prédictions et les valeurs réelles des dates comme ce qui suit :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgP8DDn5a2_r"
      },
      "source": [
        "def accuracy_adaptee(n, y_pred, y_test_list):\r\n",
        "  cmpt = 0\r\n",
        "  for i in range (0, len(y_pred)):\r\n",
        "    if abs(int(y_pred[i])-int(y_test_list[i])) < (n+1) :\r\n",
        "      cmpt +=1\r\n",
        "  return cmpt/len(y_pred)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkrx312LhfqN",
        "outputId": "35ef6c99-53d8-41b7-c7a4-653cb615f2d0"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred1, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred1, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred1, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred1, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred1, y_valid_list)))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.27741935483870966\n",
            "Taux de réponse juste à trois ans près : 0.34838709677419355\n",
            "Taux de réponse juste à cinq ans près : 0.45161290322580644\n",
            "Taux de réponse juste à sept ans près : 0.567741935483871\n",
            "Taux de réponse juste à dix ans près : 0.7419354838709677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZK3sAzyUjC2"
      },
      "source": [
        "Testons différents paramètres pour voir si nous pouvons améliorer cette performance :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2XMuH4MRYmb",
        "outputId": "e8e2d3ed-b5da-48db-c641-987bec5cc925"
      },
      "source": [
        "meilleur_n = 100\r\n",
        "meilleur_m = 2\r\n",
        "meilleure_MSE = mean_squared_error(y_validd, y_pred1)\r\n",
        "for n in range(25, 250, 25):\r\n",
        "  for m in range(2,10):\r\n",
        "    model1bis = RandomForestClassifier(n_estimators=n, max_depth=None, min_samples_split=m, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "    model1bis.fit(x_train, y_train)\r\n",
        "    y_pred1bis = model1.predict(x_valid)\r\n",
        "    MSE = mean_squared_error(y_validd, y_pred1bis)\r\n",
        "    if MSE < meilleure_MSE :\r\n",
        "      meilleur_n = n\r\n",
        "      meilleure_MSE = MSE\r\n",
        "      meilleur_m = m\r\n",
        "\r\n",
        "print(\"n :\", meilleur_n)\r\n",
        "print(\"m :\", meilleur_m)\r\n",
        "print(\"MSE :\", meilleure_MSE)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n : 100\n",
            "m : 2\n",
            "MSE : 80.06451612903226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UWPWRxdRPRF"
      },
      "source": [
        "Ce résultat n’est pas vraiment un bon résultat, et il ne change pas du résultat précédent. Nous avons donc décidé de tester un autre algorithme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cvu40vyPfNg"
      },
      "source": [
        "## SupportVectorClassifier sur les keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIUqTZRRf080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53885eac-e88b-4330-838e-40cf0598c765"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "model2 = SVC(C= 1.0, tol =0.0001)\r\n",
        "model2.fit(x_train, y_train)\r\n",
        "\r\n",
        "y_pred2 = model2.predict(x_valid)\r\n",
        "\r\n",
        "print(\"Training Accuracy :\", model2.score(x_train, y_train))\r\n",
        "print(\"Testing Accuracy :\", model2.score(x_valid, y_valid))\r\n",
        "print(\"MSE :\", mean_squared_error(y_validd, y_pred2))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy : 0.9060728744939271\n",
            "Testing Accuracy : 0.04516129032258064\n",
            "MSE : 33.26451612903226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-3UUJZRUyD"
      },
      "source": [
        "Nous pouvons déjà constater que la MSE est très inférieure à ce que nous obtenions avec le RandomForest Classifier, ce qui est signe que ce modèle est nettement plus précis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FcbArV08oqG",
        "outputId": "d49ec47b-7369-4321-f266-eb660678f31c"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred2, y_valid_list)))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.32903225806451614\n",
            "Taux de réponse juste à trois ans près : 0.4258064516129032\n",
            "Taux de réponse juste à cinq ans près : 0.6451612903225806\n",
            "Taux de réponse juste à sept ans près : 0.7870967741935484\n",
            "Taux de réponse juste à dix ans près : 0.9419354838709677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2Qk7bYxgY-t"
      },
      "source": [
        "On test maintenant de changer le taux d'apprentissage sur notre SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsR84T_tVMFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ac9c71-9727-4cd8-f83e-721fe83c0cca"
      },
      "source": [
        "meilleur_t = 0.001\r\n",
        "meilleure_MSE = mean_squared_error(y_validd, y_pred2)\r\n",
        "for t in range(1, 10):\r\n",
        "  model2bis = SVC(C= 1.0, tol =10**(-t))\r\n",
        "  model2bis.fit(x_train, y_train)\r\n",
        "  y_pred2bis = model2.predict(x_valid)\r\n",
        "  MSE = mean_squared_error(y_validd, y_pred2bis)\r\n",
        "  if MSE < meilleure_MSE :\r\n",
        "    meilleur_t = 10**(-t)\r\n",
        "    meilleure_MSE = MSE\r\n",
        "\r\n",
        "print(\"t :\", meilleur_t)\r\n",
        "print(\"MSE :\", meilleure_MSE)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t : 0.001\n",
            "MSE : 33.26451612903226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Msel9iqUE_"
      },
      "source": [
        "Testons donc avec ce seuil de tolérance :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-bYoDQ0qO3Z"
      },
      "source": [
        "model2 = SVC(C= 1.0, tol =0.001)\r\n",
        "model2.fit(x_train, y_train)\r\n",
        "\r\n",
        "y_pred2 = model2.predict(x_valid)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3OdjFRwqRxk",
        "outputId": "d36702b8-bfce-479d-e31e-62427d62d7bf"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred2, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred2, y_valid_list)))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.32903225806451614\n",
            "Taux de réponse juste à trois ans près : 0.4258064516129032\n",
            "Taux de réponse juste à cinq ans près : 0.6451612903225806\n",
            "Taux de réponse juste à sept ans près : 0.7870967741935484\n",
            "Taux de réponse juste à dix ans près : 0.9419354838709677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbg7IIWLcG9v"
      },
      "source": [
        "## RandomForestClassifier sur la distance aux centroïdes des clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huYYUg0-joz5"
      },
      "source": [
        "Appliquons maintenant les mêmes algorithmes mais aux distances de chaque article aux centroïdes de chaque cluster. En effet, celà nous permet non plus de considérer chaque keywords, mais les groupes de keywords obtenus lors de notre étape de clustering, qui seront sans doute plus pertinent d'un point de vue temporel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BHvvArIAQDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f472777-eab5-4761-d4fa-297d143316e1"
      },
      "source": [
        "model3 = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "model3.fit(x_train3, y_train3)\r\n",
        "\r\n",
        "y_pred3 = model3.predict(x_valid3)\r\n",
        "\r\n",
        "\r\n",
        "print(\"Training Accuracy :\", model3.score(x_train3, y_train3))\r\n",
        "print(\"Validating Accuracy :\", model3.score(x_valid3, y_valid3))\r\n",
        "print(\"MSE :\", mean_squared_error(y_validd, y_pred3))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy : 0.977327935222672\n",
            "Validating Accuracy : 0.09032258064516129\n",
            "MSE : 37.00645161290323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvYZGMKSkTqB"
      },
      "source": [
        "On constate que l'on obtient une bien meilleure MSE que pour le même algorithme appliqué aux keywords en one hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OaxPi_mhzfR",
        "outputId": "7ef99c7c-c4d6-4f47-e10e-8c69def5dff8"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred3, y_valid_list)))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.38064516129032255\n",
            "Taux de réponse juste à trois ans près : 0.45161290322580644\n",
            "Taux de réponse juste à cinq ans près : 0.6258064516129033\n",
            "Taux de réponse juste à sept ans près : 0.7612903225806451\n",
            "Taux de réponse juste à dix ans près : 0.896774193548387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXziIl1RkhAi"
      },
      "source": [
        "Regardons maintenant si nous souhaitons améliorer nos performances :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqR8o1eJiBFF",
        "outputId": "7659f75f-d7d4-4824-bbdd-75a0809a451f"
      },
      "source": [
        "meilleur_n = 100\r\n",
        "meilleur_m = 2\r\n",
        "meilleure_MSE = mean_squared_error(y_validd, y_pred3)\r\n",
        "for n in range(25, 250, 25):\r\n",
        "  for m in range(2,10):\r\n",
        "    model3bis = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "    model3bis.fit(x_train3, y_train3)\r\n",
        "    y_pred3bis = model3bis.predict(x_valid3)\r\n",
        "    MSE = mean_squared_error(y_validd, y_pred3bis)\r\n",
        "    if MSE < meilleure_MSE :\r\n",
        "      meilleur_n = n\r\n",
        "      meilleure_MSE = MSE\r\n",
        "      meilleur_m = m\r\n",
        "\r\n",
        "print(\"n :\", meilleur_n)\r\n",
        "print(\"m :\", meilleur_m)\r\n",
        "print(\"MSE :\", meilleure_MSE)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n : 175\n",
            "m : 3\n",
            "MSE : 29.83225806451613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu2L1q5rkmAG"
      },
      "source": [
        "On obtient donc un résultat plus performant, et équivalant au SVC appliqué aux keywords. Regardons ce modèle avec notre métrique :\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opeaZq_5qni_"
      },
      "source": [
        "model3 = RandomForestClassifier(n_estimators=175, max_depth=None, min_samples_split=5, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "model3.fit(x_train3, y_train3)\r\n",
        "\r\n",
        "y_pred3 = model3.predict(x_valid3)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbANdH5-qtPl",
        "outputId": "5f0292b1-24d5-49a5-d279-9d97ffd981a4"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred3, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred3, y_valid_list)))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.36774193548387096\n",
            "Taux de réponse juste à trois ans près : 0.4774193548387097\n",
            "Taux de réponse juste à cinq ans près : 0.6451612903225806\n",
            "Taux de réponse juste à sept ans près : 0.8129032258064516\n",
            "Taux de réponse juste à dix ans près : 0.9032258064516129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egmm4R7Picds"
      },
      "source": [
        "## SupportVectorClassifier sur la distance aux centroïdes des clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNX01sVqkwsX"
      },
      "source": [
        "Regardons donc les résultats que nous obtenons avec le SVC appliqué aux distances aux centroïdes de nos clusters :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzXRjbOVixhU",
        "outputId": "dd5fd65d-b94b-49e2-ca37-983db0dce4cf"
      },
      "source": [
        "model4 = SVC(C= 1.0, tol =0.0001)\r\n",
        "model4.fit(x_train3, y_train3)\r\n",
        "\r\n",
        "y_pred4 = model4.predict(x_valid3)\r\n",
        "\r\n",
        "print(\"Training Accuracy :\", model4.score(x_train3, y_train3))\r\n",
        "print(\"Validating Accuracy :\", model4.score(x_valid3, y_valid3))\r\n",
        "print(\"MSE :\", mean_squared_error(y_validd, y_pred4))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy : 0.08987854251012145\n",
            "Validating Accuracy : 0.03870967741935484\n",
            "MSE : 26.270967741935483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_7Dl_qhk2mD"
      },
      "source": [
        "Nous obtenons des résultats encore meilleur. Voyons si nous pouvons les améliorer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQJjyV9vjCXx",
        "outputId": "5088bad4-1a74-450c-a270-a4ba4da24ecf"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred4, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred4, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred4, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred4, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred4, y_valid_list)))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.3548387096774194\n",
            "Taux de réponse juste à trois ans près : 0.47096774193548385\n",
            "Taux de réponse juste à cinq ans près : 0.7096774193548387\n",
            "Taux de réponse juste à sept ans près : 0.832258064516129\n",
            "Taux de réponse juste à dix ans près : 0.9806451612903225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms4kqjSsjK5c",
        "outputId": "ccbc755a-7da9-463f-fd6b-55a3e7b7db47"
      },
      "source": [
        "meilleur_t = 0.0001\r\n",
        "\r\n",
        "meilleure_MSE = mean_squared_error(y_validd, y_pred4)\r\n",
        "for t in range(1, 10):\r\n",
        "  model4bis = SVC(C= 1.0, tol =10**(-t))\r\n",
        "  model4bis.fit(x_train3, y_train3)\r\n",
        "  y_pred4bis = model4.predict(x_valid3)\r\n",
        "  MSE = mean_squared_error(y_validd, y_pred4bis)\r\n",
        "  if MSE < meilleure_MSE :\r\n",
        "    meilleur_t = 10**(-t)\r\n",
        "    meilleure_MSE = MSE\r\n",
        "\r\n",
        "print(\"t :\", meilleur_t)\r\n",
        "print(\"MSE :\", meilleure_MSE)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t : 0.0001\n",
            "MSE : 26.270967741935483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLAKQ0fhlBMu"
      },
      "source": [
        "Nous n'obtenons pas de meilleurs résultats en changenant le taux d'apprentissage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQOP8Ho4mGAW"
      },
      "source": [
        "## RandomForestClassifier sur les titres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lftmCIbtuvdj"
      },
      "source": [
        "Appliquons maintenant notre modèles sur les titres :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-DqqjdDmJkB",
        "outputId": "b61847d7-69de-4b58-a1e4-676d49c58972"
      },
      "source": [
        "model5 = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "model5.fit(x_train2, y_train2)\r\n",
        "\r\n",
        "y_pred5 = model5.predict(x_valid2)\r\n",
        "\r\n",
        "\r\n",
        "print(\"Training Accuracy :\", model5.score(x_train2, y_train2))\r\n",
        "print(\"Validating Accuracy :\", model5.score(x_valid2, y_valid2))\r\n",
        "print(\"MSE :\", mean_squared_error(y_validd, y_pred5))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy : 0.9983805668016195\n",
            "Validating Accuracy : 0.03870967741935484\n",
            "MSE : 53.23225806451613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzJLBS3emUlS",
        "outputId": "fa070daf-1f1e-4747-bb24-1dfc42a04080"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred5, y_valid_list)))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.23225806451612904\n",
            "Taux de réponse juste à trois ans près : 0.3032258064516129\n",
            "Taux de réponse juste à cinq ans près : 0.5419354838709678\n",
            "Taux de réponse juste à sept ans près : 0.6967741935483871\n",
            "Taux de réponse juste à dix ans près : 0.8516129032258064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wjcRnN5maCV",
        "outputId": "9cfee8c6-303a-4234-b224-733e90576ae0"
      },
      "source": [
        "meilleur_n = 100\r\n",
        "meilleur_m = 2\r\n",
        "meilleure_MSE = mean_squared_error(y_validd, y_pred5)\r\n",
        "for n in range(25, 250, 25):\r\n",
        "  for m in range(2,10):\r\n",
        "    model5bis = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "    model5bis.fit(x_train2, y_train2)\r\n",
        "    y_pred5bis = model5bis.predict(x_valid2)\r\n",
        "    MSE = mean_squared_error(y_validd, y_pred5bis)\r\n",
        "    if MSE < meilleure_MSE :\r\n",
        "      meilleur_n = n\r\n",
        "      meilleure_MSE = MSE\r\n",
        "      meilleur_m = m\r\n",
        "\r\n",
        "print(\"n :\", meilleur_n)\r\n",
        "print(\"m :\", meilleur_m)\r\n",
        "print(\"MSE :\", meilleure_MSE)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n : 175\n",
            "m : 9\n",
            "MSE : 47.090322580645164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NouxVz2OunX-"
      },
      "source": [
        "model5 = RandomForestClassifier(n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf= 1, max_leaf_nodes=None)\r\n",
        "model5.fit(x_train2, y_train2)\r\n",
        "\r\n",
        "y_pred5 = model5.predict(x_valid2)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkSPVIPXusDM",
        "outputId": "99bd4e51-c0d5-4a24-a633-8c454b52ccfd"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred5, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred5, y_valid_list)))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.22580645161290322\n",
            "Taux de réponse juste à trois ans près : 0.3032258064516129\n",
            "Taux de réponse juste à cinq ans près : 0.5096774193548387\n",
            "Taux de réponse juste à sept ans près : 0.6903225806451613\n",
            "Taux de réponse juste à dix ans près : 0.8451612903225807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxgLcq5xmv9b"
      },
      "source": [
        "## SupportVectorClassifier sur les titres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHEbm5hFmvJ_",
        "outputId": "591fc03f-34e3-478b-f35f-ffff952b8c95"
      },
      "source": [
        "model6 = SVC(C= 1.0, tol =0.0001)\r\n",
        "model6.fit(x_train2, y_train2)\r\n",
        "\r\n",
        "y_pred6 = model6.predict(x_valid2)\r\n",
        "\r\n",
        "print(\"Training Accuracy :\", model6.score(x_train2, y_train2))\r\n",
        "print(\"Validating Accuracy :\", model6.score(x_valid2, y_valid2))\r\n",
        "print(\"MSE :\", mean_squared_error(y_validd, y_pred6))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy : 0.2242914979757085\n",
            "Validating Accuracy : 0.04516129032258064\n",
            "MSE : 42.07741935483871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4-lXCYam7xI",
        "outputId": "c2587786-6106-47f4-cc4c-683c97aa02ce"
      },
      "source": [
        "print(\"Taux de réponse juste à deux ans près : \" + str(accuracy_adaptee(2, y_pred6, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à trois ans près : \" + str(accuracy_adaptee(3, y_pred6, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à cinq ans près : \" + str(accuracy_adaptee(5, y_pred6, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à sept ans près : \" + str(accuracy_adaptee(7, y_pred6, y_valid_list)))\r\n",
        "print(\"Taux de réponse juste à dix ans près : \" + str(accuracy_adaptee(10, y_pred6, y_valid_list)))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taux de réponse juste à deux ans près : 0.3032258064516129\n",
            "Taux de réponse juste à trois ans près : 0.3741935483870968\n",
            "Taux de réponse juste à cinq ans près : 0.6064516129032258\n",
            "Taux de réponse juste à sept ans près : 0.7354838709677419\n",
            "Taux de réponse juste à dix ans près : 0.8838709677419355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs8H7gtjm_oG",
        "outputId": "4a362219-beac-4bba-840d-ee34290940b1"
      },
      "source": [
        "meilleur_t = 0.0001\r\n",
        "\r\n",
        "meilleure_MSE = mean_squared_error(y_validd, y_pred6)\r\n",
        "for t in range(1, 10):\r\n",
        "  model6bis = SVC(C= 1.0, tol =10**(-t))\r\n",
        "  model6bis.fit(x_train2, y_train2)\r\n",
        "  y_pred6bis = model6.predict(x_valid2)\r\n",
        "  MSE = mean_squared_error(y_validd, y_pred6bis)\r\n",
        "  if MSE < meilleure_MSE :\r\n",
        "    meilleur_t = 10**(-t)\r\n",
        "    meilleure_MSE = MSE\r\n",
        "\r\n",
        "print(\"t :\", meilleur_t)\r\n",
        "print(\"MSE :\", meilleure_MSE)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t : 0.0001\n",
            "MSE : 42.07741935483871\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}